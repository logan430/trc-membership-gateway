---
phase: 18-performance-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/PERFORMANCE-AUDIT.md
autonomous: true

must_haves:
  truths:
    - "N+1 query patterns documented or confirmed absent"
    - "API response time characteristics documented"
    - "Connection pooling configuration verified and documented"
    - "Discord rate limit compliance verified and documented"
    - "Memory usage baseline documented"
  artifacts:
    - path: ".planning/PERFORMANCE-AUDIT.md"
      provides: "Prioritized performance audit report"
      min_lines: 150
  key_links:
    - from: "PERFORMANCE-AUDIT.md"
      to: "AUDIT-CHECKLIST.md Section 5"
      via: "Addresses all 8 checklist items"
      pattern: "Database query efficiency|API response times|Connection pooling"
---

<objective>
Conduct comprehensive performance audit of TRC Membership Gateway

Purpose: Document performance characteristics and identify any issues BEFORE production deployment. This is an audit phase - findings are documented, not fixed.

Output: PERFORMANCE-AUDIT.md with prioritized findings covering N+1 queries, response times, connection pooling, Discord rate limits, and memory characteristics.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-performance-audit/18-RESEARCH.md
@.planning/AUDIT-CHECKLIST.md (Section 5: Performance Audit)

# Prior audit for format reference
@.planning/CODE-QUALITY-AUDIT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Execute Performance Analysis</name>
  <files>src/routes/*.ts, src/lib/prisma.ts, src/reconciliation/auto-fixer.ts, src/lib/role-assignment.ts</files>
  <action>
Perform static code analysis to evaluate performance characteristics. Do NOT modify any source files.

**1. N+1 Query Detection:**
- Grep for `findMany` and `findUnique` calls in route files
- Check each for `include` usage (good) vs loop patterns (bad)
- Document any queries inside for/forEach loops
- Verify admin/members.ts pagination uses take/skip

Command patterns:
```bash
# Find all Prisma query patterns
grep -rn "prisma\." src/routes/ --include="*.ts" | grep -E "(findMany|findUnique|findFirst)"

# Find potential N+1 patterns (query inside loop)
grep -rn -A5 "for.*of\|forEach" src/routes/ --include="*.ts" | grep -E "prisma\."
```

**2. Connection Pooling Verification:**
- Read DATABASE_URL pattern from src/lib/prisma.ts
- Verify it references port 6543 (Supabase pooler transaction mode)
- Note: Cannot verify actual connection string (contains secrets)
- Document the adapter pattern being used

**3. Discord Rate Limit Compliance:**
- Verify BATCH_SIZE and BATCH_DELAY_MS constants in auto-fixer.ts
- Verify p-retry configuration in role-assignment.ts
- Check for rate limit event listener in bot client
- Document the 2-second delay pattern

**4. Memory Baseline:**
- Check if /health endpoint includes memory info
- If not, document that memory info is NOT currently exposed
- Note: This is observation only, no changes

**5. Response Time Characteristics:**
- List all API endpoints by type (auth, dashboard, admin)
- Note complexity (database queries, external calls)
- Identify potentially slow endpoints (multiple queries, Discord API calls)

Document all findings with code references (file:line).
  </action>
  <verify>
- All 5 analysis categories completed
- Code references (file:line) documented for each finding
- N+1 patterns identified (count: 0 or list)
- Connection pooling config documented
- Discord rate limit constants verified
  </verify>
  <done>Raw performance analysis data collected from codebase</done>
</task>

<task type="auto">
  <name>Task 2: Produce Performance Audit Report</name>
  <files>.planning/PERFORMANCE-AUDIT.md</files>
  <action>
Create `.planning/PERFORMANCE-AUDIT.md` with comprehensive performance audit findings.

Use this structure (matching CODE-QUALITY-AUDIT.md format):

```markdown
# Performance Audit Report

**Project:** The Revenue Council Membership Gateway
**Audit Date:** {date}
**Auditor:** Claude (automated analysis)
**Status:** {PASSED|PASSED WITH NOTES|NEEDS ATTENTION}

## Executive Summary

| Category | Status | Finding |
|----------|--------|---------|
| N+1 Queries | {PASS/WARN/FAIL} | {brief} |
| API Response Times | {PASS/WARN/FAIL} | {brief} |
| Connection Pooling | {PASS/WARN/FAIL} | {brief} |
| Discord Rate Limits | {PASS/WARN/FAIL} | {brief} |
| Memory Management | {PASS/WARN/FAIL} | {brief} |

**Production Ready:** {Yes/Yes with caveats/No}

## Detailed Findings

### 1. N+1 Query Analysis

{Methodology, code patterns checked, results}

#### Queries Using Include (Good)
{List with file:line references}

#### Potential N+1 Patterns (Bad)
{List with file:line references, or "None found"}

### 2. API Response Time Analysis

{Endpoint categorization by complexity}

| Endpoint | DB Queries | External Calls | Risk Level |
|----------|------------|----------------|------------|
| ... | ... | ... | Low/Medium/High |

{Note: No load testing performed - static analysis only}

### 3. Connection Pooling Configuration

{Prisma adapter pattern, DATABASE_URL pattern, pooler verification}

**Verified:**
- [ ] Uses adapter pattern
- [ ] Pool created via pg.Pool
- [ ] Port 6543 expected (Supabase pooler)

### 4. Discord Rate Limit Compliance

{Constants, delay patterns, retry configuration}

| Constant | Value | Purpose | Compliant |
|----------|-------|---------|-----------|
| BATCH_SIZE | 5 | Operations per batch | Yes |
| BATCH_DELAY_MS | 2000 | Delay between batches | Yes |

### 5. Memory Management

{Current state of memory observability}

## Recommendations

### For Production (Required)
{Any blockers - likely none based on codebase quality}

### Post-Launch (Nice to Have)
{Enhancements for monitoring, observability}

## Checklist Verification

Update AUDIT-CHECKLIST.md Section 5 status based on findings.

| Item | Severity | Status | Notes |
|------|----------|--------|-------|
| Database query efficiency | High | {PASS/FAIL} | {notes} |
| API response times | Medium | {PASS/FAIL} | {notes} |
| ... | ... | ... | ... |

---
*Audit methodology: Static code analysis*
*No load testing performed*
*Findings based on code patterns, not runtime measurements*
```

Ensure report is actionable with clear pass/fail per category.
  </action>
  <verify>
- PERFORMANCE-AUDIT.md exists with 150+ lines
- All 5 categories have findings documented
- Executive summary with pass/fail per category
- Production readiness determination stated
- Recommendations section present
  </verify>
  <done>Performance audit report created with prioritized findings and production readiness assessment</done>
</task>

</tasks>

<verification>
Phase complete when:
1. Static code analysis completed for all 5 performance categories
2. PERFORMANCE-AUDIT.md created with comprehensive findings
3. Each success criteria addressed:
   - N+1 queries: documented or confirmed absent
   - API response times: characterized by complexity
   - Connection pooling: verified via code inspection
   - Discord rate limits: batch delays confirmed
   - Memory: current observability state documented
4. Report commits cleanly
</verification>

<success_criteria>
- PERFORMANCE-AUDIT.md exists at .planning/PERFORMANCE-AUDIT.md
- Report covers all 5 audit categories with code references
- Clear PASS/WARN/FAIL status per category
- Production readiness determination stated
- Actionable recommendations (if any issues found)
- No source code modifications (audit only)
</success_criteria>

<output>
After completion, create `.planning/phases/18-performance-audit/18-01-SUMMARY.md`
</output>
